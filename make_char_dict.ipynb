{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open char dictionary data file\n",
      "鬲 is a radical already\n",
      "里 is a radical already\n",
      "廴 is a radical already\n",
      "Single 廴\t廴\n",
      "Single 丑\t丑\n",
      "王 is a radical already\n",
      "Single 丈\t丈\n",
      "毛 is a radical already\n",
      "Single 为\t为\n",
      "门 is a radical already\n",
      "Single 门\t门\n",
      "衣 is a radical already\n",
      "士 is a radical already\n",
      "Single 戊\t戊\n",
      "勹 is a radical already\n",
      "Single 勹\t勹\n",
      "豸 is a radical already\n",
      "Single 豸\t豸\n",
      "黃 is a radical already\n",
      "攵 is a radical already\n",
      "Single 攵\t攵\n",
      "缶 is a radical already\n",
      "Single 缶\t缶\n",
      "麦 is a radical already\n",
      "戈 is a radical already\n",
      "兀 is a radical already\n",
      "子 is a radical already\n",
      "Single 子\t子\n",
      "丬 is a radical already\n",
      "Single 丬\t丬\n",
      "Single 乍\t乍\n",
      "行 is a radical already\n",
      "舟 is a radical already\n",
      "Single 舟\t舟\n",
      "皿 is a radical already\n",
      "Single 皿\t皿\n",
      "香 is a radical already\n",
      "Single 香\t⾹\n",
      "玄 is a radical already\n",
      "Single 丩\t丩\n",
      "山 is a radical already\n",
      "Single 山\t山\n",
      "龠 is a radical already\n",
      "Single 冘\t冘\n",
      "邑 is a radical already\n",
      "止 is a radical already\n",
      "Single 止\t止\n",
      "Single 且\t且\n",
      "Single 书\t书\n",
      "戶 is a radical already\n",
      "户 is a radical already\n",
      "由 is a radical already\n",
      "Single 由\t由\n",
      "弋 is a radical already\n",
      "聿 is a radical already\n",
      "Single 朿\t朿\n",
      "支 is a radical already\n",
      "Single 久\t久\n",
      "風 is a radical already\n",
      "㔾 is a radical already\n",
      "Single 㔾\t㔾\n",
      "几 is a radical already\n",
      "Single 几\t几\n",
      "至 is a radical already\n",
      "文 is a radical already\n",
      "忄 is a radical already\n",
      "Single 忄\t忄\n",
      "黾 is a radical already\n",
      "彡 is a radical already\n",
      "Single 彡\t彡\n",
      "乛 is a radical already\n",
      "Single 乛\t乛\n",
      "齒 is a radical already\n",
      "靣 is a radical already\n",
      "Single 曲\t曲\n",
      "歯 is a radical already\n",
      "亠 is a radical already\n",
      "已 is a radical already\n",
      "Single 已\t已\n",
      "虎 is a radical already\n",
      "卩 is a radical already\n",
      "Single 卩\t卩\n",
      "韭 is a radical already\n",
      "甘 is a radical already\n",
      "Single 甘\t甘\n",
      "龵 is a radical already\n",
      "Single 龵\t龵\n",
      "黒 is a radical already\n",
      "Single 孑\t孑\n",
      "⺁ is a radical already\n",
      "Single ⺁\t⺁\n",
      "Single \t\n",
      "Single \t\n",
      "Single \t\n",
      "⺄ is a radical already\n",
      "Single ⺄\t⺄\n",
      "⺈ is a radical already\n",
      "Single ⺈\t⺈\n",
      "⺋ is a radical already\n",
      "Single ⺋\t⺋\n",
      "Single \t\n",
      "⺗ is a radical already\n",
      "Single ⺗\t⺗\n",
      "Single \t\n",
      "Single \t\n",
      "Single \t\n",
      "⺧ is a radical already\n",
      "Single ⺧\t⺧\n",
      "Single \t\n",
      "⺪ is a radical already\n",
      "Single ⺪\t⺪\n",
      "艮 is a radical already\n",
      "Single 艮\t艮\n",
      "冃 is a radical already\n",
      "丿 is a radical already\n",
      "Single 丿\t丿\n",
      "羽 is a radical already\n",
      "Single 永\t永\n",
      "匕 is a radical already\n",
      "Single 匕\t匕\n",
      "长 is a radical already\n",
      "Single 长\t长\n",
      "耂 is a radical already\n",
      "Single 耂\t耂\n",
      "丨 is a radical already\n",
      "Single 丨\t丨\n",
      "Single 本\t本\n",
      "纟 is a radical already\n",
      "Single 纟\t纟\n",
      "母 is a radical already\n",
      "Single 母\t母\n",
      "用 is a radical already\n",
      "老 is a radical already\n",
      "Single 凸\t凸\n",
      "小 is a radical already\n",
      "Single 小\t小\n",
      "宀 is a radical already\n",
      "Single 宀\t宀\n",
      "巾 is a radical already\n",
      "Single 巾\t巾\n",
      "尣 is a radical already\n",
      "Single 册\t册\n",
      "寸 is a radical already\n",
      "Single 寸\t寸\n",
      "卜 is a radical already\n",
      "Single 卜\t卜\n",
      "雨 is a radical already\n",
      "木 is a radical already\n",
      "Single 木\t木\n",
      "匚 is a radical already\n",
      "Single 匚\t匚\n",
      "冖 is a radical already\n",
      "Single 冖\t冖\n",
      "甩 is a radical already\n",
      "首 is a radical already\n",
      "辵 is a radical already\n",
      "非 is a radical already\n",
      "Single 非\t非\n",
      "韦 is a radical already\n",
      "Single 韦\t韦\n",
      "无 is a radical already\n",
      "礻 is a radical already\n",
      "Single 礻\t礻\n",
      "穴 is a radical already\n",
      "人 is a radical already\n",
      "Single 人\t人\n",
      "巳 is a radical already\n",
      "Single 巳\t巳\n",
      "Single 乐\t乐\n",
      "Single 丐\t丐\n",
      "自 is a radical already\n",
      "Single 自\t自\n",
      "麻 is a radical already\n",
      "皮 is a radical already\n",
      "Single 皮\t皮\n",
      "彐 is a radical already\n",
      "Single 彐\t彐\n",
      "尸 is a radical already\n",
      "Single 尸\t尸\n",
      "足 is a radical already\n",
      "Single 尺\t尺\n",
      "钅 is a radical already\n",
      "Single 钅\t钅\n",
      "黍 is a radical already\n",
      "Single 世\t世\n",
      "Single 巴\t巴\n",
      "儿 is a radical already\n",
      "厶 is a radical already\n",
      "Single 厶\t厶\n",
      "甲 is a radical already\n",
      "Single 甲\t甲\n",
      "灬 is a radical already\n",
      "Single 灬\t灬\n",
      "目 is a radical already\n",
      "Single 目\t目\n",
      "言 is a radical already\n",
      "Single 言\t言\n",
      "手 is a radical already\n",
      "Single 手\t手\n",
      "Single 年\t年\n",
      "辛 is a radical already\n",
      "氵 is a radical already\n",
      "Single 氵\t氵\n",
      "黄 is a radical already\n",
      "食 is a radical already\n",
      "貝 is a radical already\n",
      "白 is a radical already\n",
      "Single 白\t白\n",
      "口 is a radical already\n",
      "Single 口\t口\n",
      "鼻 is a radical already\n",
      "阜 is a radical already\n",
      "Single 未\t未\n",
      "酉 is a radical already\n",
      "Single 酉\t酉\n",
      "饣 is a radical already\n",
      "Single 饣\t饣\n",
      "Single 丹\t丹\n",
      "虫 is a radical already\n",
      "Single 虫\t虫\n",
      "金 is a radical already\n",
      "凵 is a radical already\n",
      "Single 凵\t凵\n",
      "片 is a radical already\n",
      "Single 片\t片\n",
      "禸 is a radical already\n",
      "釆 is a radical already\n",
      "音 is a radical already\n",
      "见 is a radical already\n",
      "Single 见\t见\n",
      "禾 is a radical already\n",
      "革 is a radical already\n",
      "Single 革\t革\n",
      "八 is a radical already\n",
      "Single 八\t八\n",
      "Single 柬\t柬\n",
      "丷 is a radical already\n",
      "Single 丷\t丷\n",
      "㣺 is a radical already\n",
      "弓 is a radical already\n",
      "Single 弓\t弓\n",
      "齐 is a radical already\n",
      "龙 is a radical already\n",
      "旡 is a radical already\n",
      "Single 旡\t旡\n",
      "走 is a radical already\n",
      "Single 乑\t乑\n",
      "Single 也\t也\n",
      "尢 is a radical already\n",
      "Single 尢\t尢\n",
      "月 is a radical already\n",
      "Single 月\t月\n",
      "Single 末\t末\n",
      "罒 is a radical already\n",
      "Single 罒\t罒\n",
      "戸 is a radical already\n",
      "立 is a radical already\n",
      "牙 is a radical already\n",
      "Single 牙\t牙\n",
      "丶 is a radical already\n",
      "Single 丶\t丶\n",
      "大 is a radical already\n",
      "Single 束\t束\n",
      "青 is a radical already\n",
      "又 is a radical already\n",
      "Single 又\t又\n",
      "廾 is a radical already\n",
      "扌 is a radical already\n",
      "Single 扌\t扌\n",
      "阝 is a radical already\n",
      "Single 阝\t阝\n",
      "耳 is a radical already\n",
      "Single 耳\t耳\n",
      "屮 is a radical already\n",
      "玉 is a radical already\n",
      "見 is a radical already\n",
      "厂 is a radical already\n",
      "Single 厂\t厂\n",
      "Single 廿\t廿\n",
      "氏 is a radical already\n",
      "Single 氏\t氏\n",
      "龰 is a radical already\n",
      "Single 龰\t龰\n",
      "父 is a radical already\n",
      "Single 及\t及\n",
      "身 is a radical already\n",
      "Single 身\t身\n",
      "臼 is a radical already\n",
      "Single 臼\t臼\n",
      "鬼 is a radical already\n",
      "冂 is a radical already\n",
      "Single 冂\t冂\n",
      "瓜 is a radical already\n",
      "Single 瓜\t瓜\n",
      "西 is a radical already\n",
      "竜 is a radical already\n",
      "亻 is a radical already\n",
      "Single 亻\t亻\n",
      "犭 is a radical already\n",
      "Single 犭\t犭\n",
      "辶 is a radical already\n",
      "Single 辶\t辶\n",
      "衤 is a radical already\n",
      "Single 衤\t衤\n",
      "贝 is a radical already\n",
      "Single 贝\t贝\n",
      "㓁 is a radical already\n",
      "Single 曳\t曳\n",
      "Single 九\t九\n",
      "示 is a radical already\n",
      "Single 示\t示\n",
      "飞 is a radical already\n",
      "Single 飞\t飞\n",
      "火 is a radical already\n",
      "Single 乎\t乎\n",
      "髟 is a radical already\n",
      "女 is a radical already\n",
      "Single 女\t女\n",
      "彑 is a radical already\n",
      "Single 彑\t彑\n",
      "冫 is a radical already\n",
      "Single 冫\t冫\n",
      "申 is a radical already\n",
      "Single 申\t申\n",
      "血 is a radical already\n",
      "Single 专\t专\n",
      "高 is a radical already\n",
      "牛 is a radical already\n",
      "Single 牛\t牛\n",
      "Single 禹\t禹\n",
      "歹 is a radical already\n",
      "Single 东\t东\n",
      "爿 is a radical already\n",
      "Single 爿\t爿\n",
      "夂 is a radical already\n",
      "Single 夂\t夂\n",
      "Single 重\t重\n",
      "Single 㠯\t㠯\n",
      "Single 央\t央\n",
      "Single 冉\t冉\n",
      "Single 戉\t戉\n",
      "工 is a radical already\n",
      "Single 工\t工\n",
      "米 is a radical already\n",
      "Single 米\t米\n",
      "麥 is a radical already\n",
      "艸 is a radical already\n",
      "Single 凹\t凹\n",
      "毌 is a radical already\n",
      "Single 毌\t毌\n",
      "曰 is a radical already\n",
      "Single 曰\t曰\n",
      "爪 is a radical already\n",
      "Single 爪\t爪\n",
      "乡 is a radical already\n",
      "Single 乡\t乡\n",
      "黹 is a radical already\n",
      "覀 is a radical already\n",
      "田 is a radical already\n",
      "Single 田\t田\n",
      "一 is a radical already\n",
      "Single 一\t一\n",
      "矢 is a radical already\n",
      "Single 龶\t龶\n",
      "十 is a radical already\n",
      "Single 十\t十\n",
      "舌 is a radical already\n",
      "囗 is a radical already\n",
      "Single 囗\t囗\n",
      "Single 龴\t龴\n",
      "川 is a radical already\n",
      "Single 川\t川\n",
      "心 is a radical already\n",
      "Single 心\t心\n",
      "斉 is a radical already\n",
      "乚 is a radical already\n",
      "Single 乚\t乚\n",
      "入 is a radical already\n",
      "Single 入\t入\n",
      "疒 is a radical already\n",
      "Single 疒\t疒\n",
      "肉 is a radical already\n",
      "Single 肉\t肉\n",
      "Single 㐆\t㐆\n",
      "臣 is a radical already\n",
      "Single 臣\t臣\n",
      "糸 is a radical already\n",
      "彳 is a radical already\n",
      "Single 彳\t彳\n",
      "石 is a radical already\n",
      "干 is a radical already\n",
      "Single 干\t干\n",
      "己 is a radical already\n",
      "Single 己\t己\n",
      "羊 is a radical already\n",
      "讠 is a radical already\n",
      "Single 讠\t讠\n",
      "Single 熏\t熏\n",
      "乙 is a radical already\n",
      "Single 乙\t乙\n",
      "歺 is a radical already\n",
      "民 is a radical already\n",
      "Single 民\t民\n",
      "耒 is a radical already\n",
      "豕 is a radical already\n",
      "艹 is a radical already\n",
      "瓦 is a radical already\n",
      "Single 瓦\t瓦\n",
      "车 is a radical already\n",
      "Single 车\t车\n",
      "二 is a radical already\n",
      "犬 is a radical already\n",
      "Single 犬\t犬\n",
      "攴 is a radical already\n",
      "电 is a radical already\n",
      "广 is a radical already\n",
      "Single 广\t广\n",
      "Single 州\t州\n",
      "刂 is a radical already\n",
      "Single 刂\t刂\n",
      "Single 疌\t疌\n",
      "日 is a radical already\n",
      "Single 日\t日\n",
      "土 is a radical already\n",
      "Single 我\t我\n",
      "Single 禺\t禺\n",
      "而 is a radical already\n",
      "玊 is a radical already\n",
      "Single 巨\t巨\n",
      "才 is a radical already\n",
      "Single 才\t才\n",
      "疋 is a radical already\n",
      "Single 疋\t疋\n",
      "Single 円\t円\n",
      "生 is a radical already\n",
      "Single 生\t生\n",
      "夊 is a radical already\n",
      "Single 夊\t夊\n",
      "Single 肃\t肃\n",
      "爻 is a radical already\n",
      "牜 is a radical already\n",
      "Single 牜\t牜\n",
      "飠 is a radical already\n",
      "谷 is a radical already\n",
      "Single 谷\t谷\n",
      "齿 is a radical already\n",
      "Single 齿\t齿\n",
      "Single 㐅\t㐅\n",
      "Single 头\t头\n",
      "巜 is a radical already\n",
      "豆 is a radical already\n",
      "Single 豆\t豆\n",
      "气 is a radical already\n",
      "斗 is a radical already\n",
      "Single 斗\t斗\n",
      "亅 is a radical already\n",
      "Single 亅\t亅\n",
      "黽 is a radical already\n",
      "Single 黽\t黽\n",
      "Single 粛\t粛\n",
      "Single 卝\t卝\n",
      "龍 is a radical already\n",
      "隶 is a radical already\n",
      "Single 隶\t隶\n",
      "比 is a radical already\n",
      "Single 比\t比\n",
      "門 is a radical already\n",
      "韋 is a radical already\n",
      "竹 is a radical already\n",
      "毋 is a radical already\n",
      "Single 毋\t毋\n",
      "鱼 is a radical already\n",
      "Single 来\t来\n",
      "Single 乗\t乗\n",
      "面 is a radical already\n",
      "Single 面\t⾯\n",
      "Single 為\t為\n",
      "Single 卐\t卐\n",
      "Single 孓\t孓\n",
      "Single 㐁\t㐁\n",
      "Single 㸦\t㸦\n",
      "风 is a radical already\n",
      "氺 is a radical already\n",
      "匸 is a radical already\n",
      "Single 匸\t匸\n",
      "Single 乄\t乄\n",
      "角 is a radical already\n",
      "Single 角\t角\n",
      "朩 is a radical already\n",
      "Single 朩\t朩\n",
      "Single 卌\t卌\n",
      "刁 is a radical already\n",
      "馬 is a radical already\n",
      "糹 is a radical already\n",
      "頁 is a radical already\n",
      "Single 頁\t頁\n",
      "龜 is a radical already\n",
      "Single 龜\t龜\n",
      "殳 is a radical already\n",
      "罓 is a radical already\n",
      "页 is a radical already\n",
      "Single 页\t页\n",
      "Single 曱\t曱\n",
      "羋 is a radical already\n",
      "鹵 is a radical already\n",
      "刀 is a radical already\n",
      "Single 䍏\t䍏\n",
      "Single 孒\t孒\n",
      "Single 㐧\t㐧\n",
      "Single 爲\t爲\n",
      "夕 is a radical already\n",
      "骨 is a radical already\n",
      "黑 is a radical already\n",
      "卤 is a radical already\n",
      "車 is a radical already\n",
      "Single 車\t車\n",
      "Single 乜\t乜\n",
      "色 is a radical already\n",
      "襾 is a radical already\n",
      "Single 襾\t襾\n",
      "力 is a radical already\n",
      "釒 is a radical already\n",
      "Single 釒\t釒\n",
      "鳥 is a radical already\n",
      "肀 is a radical already\n",
      "鼠 is a radical already\n",
      "Single 丏\t丏\n",
      "Single 卍\t卍\n",
      "Single 㐄\t㐄\n",
      "靑 is a radical already\n",
      "Single 肅\t肅\n",
      "魚 is a radical already\n",
      "Single 朱\t朱\n",
      "赤 is a radical already\n",
      "欠 is a radical already\n",
      "Single 欠\t欠\n",
      "虍 is a radical already\n",
      "乁 is a radical already\n",
      "Single 乁\t乁\n",
      "矛 is a radical already\n",
      "赱 is a radical already\n",
      "齊 is a radical already\n",
      "隹 is a radical already\n",
      "Single 隹\t隹\n",
      "幺 is a radical already\n",
      "亀 is a radical already\n",
      "Single 戼\t戼\n",
      "癶 is a radical already\n",
      "訁 is a radical already\n",
      "Single 訁\t訁\n",
      "鬥 is a radical already\n",
      "飛 is a radical already\n",
      "Single 飛\t飛\n",
      "鼓 is a radical already\n",
      "斤 is a radical already\n",
      "Single 亊\t亊\n",
      "鼡 is a radical already\n",
      "Single 鼡\t鼡\n",
      "巛 is a radical already\n",
      "鸟 is a radical already\n",
      "舛 is a radical already\n",
      "乀 is a radical already\n",
      "Single 乀\t乀\n",
      "爫 is a radical already\n",
      "鹿 is a radical already\n",
      "马 is a radical already\n",
      "Single 亜\t亜\n",
      "Single 兂\t兂\n",
      "長 is a radical already\n",
      "Single 丣\t丣\n",
      "镸 is a radical already\n",
      "水 is a radical already\n",
      "Single 㱐\t㱐\n",
      "网 is a radical already\n",
      "髙 is a radical already\n",
      "龟 is a radical already\n",
      "方 is a radical already\n",
      "辰 is a radical already\n",
      "Single 发\t发\n",
      "鼎 is a radical already\n",
      "Single 丱\t丱\n",
      "鬯 is a radical already\n",
      "Single 東\t東\n",
      "Single 承\t承\n",
      "Single 龴\t厶\n",
      "Single 孑\t子\n",
      "Single 𫠣\t𫠣\n",
      "Single 𠁁\t𠁁\n",
      "Single 𠂎\t𠂎\n",
      "Single 𠃊\t𠃊\n",
      "Single 𠃌\t𠃌\n",
      "Single 𠃓\t𠃓\n",
      "Single 𡗗\t𡗗\n",
      "Single 𣎳\t𣎳\n",
      "Single 𣥂\t𣥂\n",
      "𦣝 is a radical already\n",
      "Single 𦣝\t𦣝\n",
      "Single 𦣞\t𦣞\n",
      "Single 𧰨\t𧰨\n",
      "Non-radical tokens found\n",
      "③\n",
      "⑮\n",
      "△\n",
      "〢\n",
      "コ\n",
      "ス\n",
      "ユ\n",
      "㇇\n",
      "㇉\n",
      "㇏\n",
      "㇒\n",
      "㇓\n",
      "㇣\n",
      "𠁣\n",
      "𠃋\n",
      "𠃍\n",
      "𠃎\n",
      "𠃑\n",
      "𠃛\n",
      "𠄎\n",
      "𡿨\n",
      "𥘅\n",
      "𩰊\n",
      "𩰋\n",
      "[7153, 299, 0]\n",
      "len(mnemonics_words)=6480\n",
      "len(charfreq_wordset)=12042\n",
      "len(dict_wordset)=7873\n",
      "len(wordset)=15325\n",
      "Before len(char_dict)=9372\n",
      "len(wordset)=15324\n",
      "len(char_decompositions)=27414\n",
      "len(new_wordlist)=15324\n",
      "After len(char_dict)=9372\n",
      "Dictionary has been written to char_dict.xlsx\n",
      "written=10677\n",
      "In wordset but not in final list: 6179\n",
      "Not in wordset (new components): 227\n",
      "0:00:22.087786\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import readchar\n",
    "import hanzidentifier\n",
    "from pinyin import get as get_pinyin\n",
    "from collections import namedtuple\n",
    "from chin_dict.chindict import ChinDict\n",
    "from hanzipy.decomposer import HanziDecomposer\n",
    "from hanzipy.dictionary import HanziDictionary\n",
    "from dragonmapper.transcriptions import numbered_to_accented\n",
    "from tools_configs import *\n",
    "from os.path import join\n",
    "\n",
    "rad_database = Radicals()\n",
    "rad_database.load_radical_data()\n",
    "radicals = rad_database.radicals()\n",
    "\n",
    "if rad_database.is_none():\n",
    "    print(\"Error loading data\")\n",
    "    exit()\n",
    "\n",
    "cd = ChinDict()\n",
    "\n",
    "start_datetime = datetime.datetime.now()\n",
    "now_str = start_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "MAX_APPEARANCES = 20\n",
    "MAX_BUILD_ITEMS = 100\n",
    "MAX_BUILD_ITEMS = 100000\n",
    "\n",
    "BUILD_DICT_DATA = False\n",
    "CONVERT_TO_PLECO = True  #\n",
    "\n",
    "CHAR_DICT_FILE = \"char_dict.json\"\n",
    "\n",
    "print(\"Open char dictionary data file\")\n",
    "try:\n",
    "    with open(join(DATA_DIR, CHAR_DICT_FILE), \"r\", encoding=\"utf-8\") as fread:\n",
    "        char_dict = json.load(fread)\n",
    "except:\n",
    "    print(f\"No file {CHAR_DICT_FILE}\")\n",
    "\n",
    "char_decompositions = {}\n",
    "\n",
    "build_ids_radical_perfect()\n",
    "\n",
    "mnemonics_words = set()\n",
    "with open(join(DATA_DIR, \"mnemonics.json\"), \"r\", encoding=\"utf-8\") as fread:\n",
    "    mnemonics = json.load(fread)\n",
    "    mnemonics_words.update(mnemonics.keys())\n",
    "\n",
    "    for key in mnemonics:\n",
    "        text = \"\".join(mnemonics[key])\n",
    "\n",
    "        words = set(regex.findall(PATTERN_ZH, text))\n",
    "        mnemonics_words.update(words)\n",
    "\n",
    "    print(f\"{len(mnemonics_words)=}\")\n",
    "\n",
    "with open(join(WORDLIST_DIR, \"IDS_dictionary_radical_perfect.txt\"), \"r\", encoding=\"utf-8\") as fread:\n",
    "    lines = fread.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        head, decomp = line.strip().split(\":\")\n",
    "\n",
    "        char_decompositions[head] = decomp.replace(\" \", \"\")\n",
    "\n",
    "# with open(join(WORDLIST_DIR, \"dic_words_set.txt\"), \"r\", encoding=\"utf-8\") as fread:\n",
    "#     wordset.update(fread.read())\n",
    "\n",
    "dict_wordset = set()\n",
    "with open(join(WORDLIST_DIR, \"dic_words_set.txt\"), \"r\", encoding=\"utf-8\") as fread:\n",
    "    dict_wordset.update(fread.read())\n",
    "\n",
    "wordset_freq = {}\n",
    "charfreq_wordset = set()\n",
    "wordset = set()\n",
    "\n",
    "with open(join(WORDLIST_DIR, \"chinese_charfreq_simpl_trad.txt\"), \"r\", encoding=\"utf-8\") as fread:\n",
    "    next(fread)\n",
    "    contents = fread.read()\n",
    "\n",
    "    charfreq_wordset.update(contents)\n",
    "\n",
    "    wordset = charfreq_wordset | dict_wordset | mnemonics_words\n",
    "\n",
    "    print(f\"{len(charfreq_wordset)=}\")\n",
    "    print(f\"{len(dict_wordset)=}\")\n",
    "    print(f\"{len(wordset)=}\")\n",
    "\n",
    "    if \"\\n\" in wordset:\n",
    "        wordset.remove(\"\\n\")\n",
    "\n",
    "    if \" \" in wordset:\n",
    "        wordset.remove(\" \")\n",
    "\n",
    "    wordset_freq = {word: num + 1 for num, word in enumerate(contents.split(\"\\n\"))}\n",
    "\n",
    "\n",
    "def keyboard_handler(signum, frame):\n",
    "    msg = \"Ctrl-c was pressed. Do you really want to exit? y/n \"\n",
    "    print(msg, end=\"\", flush=True)\n",
    "    res = readchar.readchar()\n",
    "\n",
    "    if res == \"y\":\n",
    "        print(\"\")\n",
    "        print(\"Saving data and quiting...\")\n",
    "        with open(CHAR_DICT_FILE, \"w\", encoding=\"utf-8\") as fwrite:\n",
    "            json.dump(char_dict, fwrite, indent=4, ensure_ascii=False)\n",
    "\n",
    "        print(\" done.\")\n",
    "\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(\"\", end=\"\\r\", flush=True)\n",
    "\n",
    "        print(\" \" * len(msg), end=\"\", flush=True)  # clear the printed line\n",
    "        print(\"    \", end=\"\\r\", flush=True)\n",
    "\n",
    "\n",
    "PATTERN_PY = r\"\\[(.+)\\]\"\n",
    "\n",
    "\n",
    "def remove_non_chinese(word):\n",
    "    if match_chinese := regex.findall(PATTERN_ZH, word):\n",
    "        return match_chinese[0][0]  # Remove non Chinese characters\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def components_from_tree(tree, char):\n",
    "    tree_matches = regex.findall(PATTERN_ZH, tree)\n",
    "    if char in tree_matches:\n",
    "        tree_matches.remove(char)  # Remove parent character\n",
    "\n",
    "    return None if len(tree_matches) == 0 else tree_matches\n",
    "\n",
    "\n",
    "def get_radicals(char):\n",
    "    decomposition = decomposer.decompose(char, decomposition_type=2)\n",
    "\n",
    "    radicals = decomposition[\"components\"] if decomposition else []\n",
    "\n",
    "    # Decomposition is same as original char => No components\n",
    "    if len(radicals) == 1 and radicals[0] == char:\n",
    "        radicals = []\n",
    "\n",
    "    return radicals\n",
    "\n",
    "\n",
    "# tree = decomposer.tree(\"恭\")\n",
    "wordlist = sorted(list(wordset))\n",
    "\n",
    "if BUILD_DICT_DATA:\n",
    "    char_dict = {}\n",
    "\n",
    "    searcher = HanziDictionary()\n",
    "    result = searcher.definition_lookup(\"龋\", script_type=\"simplified\")\n",
    "\n",
    "    decomposer = HanziDecomposer()\n",
    "\n",
    "    # res = decomposer.tree(\"寰\")\n",
    "\n",
    "flog = open(\"log.txt\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "LookupType = namedtuple(\n",
    "    \"LookupType\",\n",
    "    [\"character\", \"found\", \"meaning\", \"pinyin\", \"components\", \"tree\"],\n",
    "    defaults=(\"\", False, [], \"\", [], \"\"),\n",
    ")\n",
    "\n",
    "\n",
    "def is_in_char_dict(char):\n",
    "    if char in char_dict and char_dict[char][\"meaning\"]:\n",
    "        return True\n",
    "    elif rad_database.is_radical_variant(char):\n",
    "        norminal = rad_database.norminal(char)\n",
    "        return norminal in char_dict and char_dict[norminal][\"meaning\"]\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def hanzipy_lookup(char):\n",
    "    found = False\n",
    "    results = []\n",
    "    meanings = []\n",
    "    pinyins = []\n",
    "    # pinyin = \"\"\n",
    "\n",
    "    try:\n",
    "        results = searcher.definition_lookup(char, script_type=\"simplified\")\n",
    "        found = True\n",
    "\n",
    "        # If first item is surname, move it to back\n",
    "        if len(results) > 1 and results[0][\"pinyin\"][0].isupper():\n",
    "            first = results[0]\n",
    "            del results[0]\n",
    "            results.append(first)\n",
    "\n",
    "        for result in results:\n",
    "            meanings.append(result[\"definition\"].split(\"/\"))\n",
    "            pinyins.append(numbered_to_accented(result[\"pinyin\"]))\n",
    "\n",
    "        pinyins = list(dict.fromkeys(pinyins))\n",
    "        # pinyin = \"/\".join(pinyins)\n",
    "    except:\n",
    "        print(\"No meaning\")\n",
    "\n",
    "    return found, meanings, pinyins\n",
    "\n",
    "\n",
    "def lookup_symbol(char):\n",
    "    lookup = LookupType()\n",
    "\n",
    "    if not char:\n",
    "        print(f\"Wrong character: {char}\")\n",
    "        return lookup\n",
    "\n",
    "    found, meanings, pinyins = hanzipy_lookup(char)\n",
    "\n",
    "    if not found:\n",
    "        if rad_database.is_radical_variant(char):\n",
    "            result = rad_database.lookup(char)\n",
    "\n",
    "            return LookupType(\n",
    "                char,\n",
    "                found=True,\n",
    "                meaning=[[result[\"meaning\"]]],\n",
    "                pinyin=[result[\"pinyin\"]],\n",
    "            )\n",
    "        else:\n",
    "            return lookup\n",
    "\n",
    "    decomposition = decomposer.tree(char)\n",
    "\n",
    "    # Normalize components\n",
    "    norminal_components = [\n",
    "        rad_database.norminal(comp) if rad_database.is_radical_variant(comp) else comp\n",
    "        for comp in decomposition[\"components\"]\n",
    "    ]\n",
    "\n",
    "    return LookupType(\n",
    "        char,\n",
    "        found=True,\n",
    "        meaning=meanings,\n",
    "        pinyin=pinyins,\n",
    "        components=norminal_components,\n",
    "        tree=decomposition[\"tree\"],\n",
    "    )\n",
    "\n",
    "\n",
    "if BUILD_DICT_DATA:\n",
    "    for num, org_char in enumerate(wordlist[:MAX_BUILD_ITEMS]):\n",
    "        # org_char = \"打\"\n",
    "\n",
    "        char = remove_non_chinese(org_char)\n",
    "\n",
    "        if not char:\n",
    "            continue\n",
    "\n",
    "        print(f\"{num+1}/{len(wordlist)}: {char}\")\n",
    "\n",
    "        lookup = lookup_symbol(char)\n",
    "\n",
    "        if is_in_char_dict(char):  # fmt: skip\n",
    "            print(f\"Already in dict: {char}\")\n",
    "\n",
    "        if not lookup.found:\n",
    "            flog.write(f\"{org_char}\\tWrong character\\n\")\n",
    "            print(f\"Wrong character: {org_char}\")\n",
    "\n",
    "            continue\n",
    "\n",
    "        char_dict[char] = {\n",
    "            \"meaning\": lookup.meaning,\n",
    "            \"pinyin\": lookup.pinyin,\n",
    "            \"components\": lookup.components,\n",
    "            \"tree\": lookup.tree,\n",
    "        }\n",
    "\n",
    "        results = cd.lookup_char(char)\n",
    "        radical = results.radical.character\n",
    "        # if radical not in lookup.components:\n",
    "        #     print(f'{char} added {results.radical}')\n",
    "        #     lookup.components.append(radical)\n",
    "\n",
    "        if lookup.components:\n",
    "            for comp_char in lookup.components:\n",
    "                if is_in_char_dict(comp_char):  # fmt: skip\n",
    "                    print(f\"Already in dict: {comp_char}\")\n",
    "                    # flog.write(f\"{org_char}\\tAlready in dict\\n\")\n",
    "                    continue\n",
    "\n",
    "                comp_lookup = lookup_symbol(comp_char)\n",
    "\n",
    "                if not comp_lookup.found:\n",
    "                    flog.write(f\"{comp_char}\\tWrong character\\n\")\n",
    "                    print(f\"Wrong character: {org_char}\")\n",
    "                    continue\n",
    "                else:\n",
    "                    char_dict[comp_char] = {\n",
    "                        \"meaning\": comp_lookup.meaning,\n",
    "                        \"pinyin\": comp_lookup.pinyin,\n",
    "                        \"components\": comp_lookup.components,\n",
    "                        \"tree\": comp_lookup.tree,\n",
    "                    }\n",
    "\n",
    "    print(f\"{len(char_dict)=}\")\n",
    "    with open(CHAR_DICT_FILE, \"w\", encoding=\"utf-8\") as fwrite:\n",
    "        json.dump(char_dict, fwrite, indent=4, ensure_ascii=False, sort_keys=True)\n",
    "\n",
    "\n",
    "# s1 = set(char_dict.keys())\n",
    "# s2 = set(decomposer.characters.keys())\n",
    "\n",
    "# print(f\"In char dict but not in hanzipy {len(s1-s2)=}\")\n",
    "# print(f\"In hanzipy but not in char dict {len(s2-s1)=}\")\n",
    "\n",
    "\n",
    "def replace_chinese_in_tree(match_obj):\n",
    "    if match_obj.group(1) is not None:\n",
    "        key = match_obj.group(1)\n",
    "        pinyin = \"\"\n",
    "        meaning = \"\"\n",
    "\n",
    "        if rad_database.is_radical_variant(key):\n",
    "            item = rad_database.lookup(key)\n",
    "            pinyin = item[\"pinyin\"]\n",
    "            meaning = f\"{item['meaning']} (#{item['number']})\"\n",
    "        elif key in char_dict:\n",
    "            item = char_dict[key]\n",
    "            meaning = item[\"meaning\"][0][0] if item[\"meaning\"] else \"(no meaning)\"\n",
    "            pinyin = item[\"pinyin\"][0]\n",
    "\n",
    "        return f\"{pleco_make_blue(key)} {pleco_make_italic(pinyin)}\"\n",
    "        # return pleco_make_blue(match_obj.group(1))\n",
    "\n",
    "\n",
    "def make_chinese_blue(match_obj):\n",
    "    if match_obj.group(1) is not None:\n",
    "        key = match_obj.group(1)\n",
    "\n",
    "        return f\"{pleco_make_blue(key)}\"\n",
    "        # return pleco_make_blue(match_obj.group(1))\n",
    "\n",
    "\n",
    "def replace_chinese_blue(match_obj):\n",
    "    if match_obj.group(1) is not None:\n",
    "        key = match_obj.group(1)\n",
    "\n",
    "        return f\"{pleco_make_blue(key)}\"\n",
    "\n",
    "\n",
    "def replace_numbers(match_obj):\n",
    "    if match_obj.group(1) is not None:\n",
    "        hex_val = hex(int(match_obj.group(1)))\n",
    "        return f\"{PC_DOTTED_SQUARE} {hex_val[2:].upper()}\"\n",
    "        # return pleco_make_blue(match_obj.group(1))\n",
    "\n",
    "\n",
    "def find_freq(word):\n",
    "    return wordset_freq[word] if word in wordset_freq else BIGNUM\n",
    "\n",
    "\n",
    "def sort_by_freq(list_chars):\n",
    "    items = sorted([(word, find_freq(word)) for word in list_chars], key=lambda x: (x[1], x[0]))\n",
    "\n",
    "    return [word for word, order in items]\n",
    "\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "def complex_dict_to_excel(data_dict, file_path):\n",
    "    \"\"\"\n",
    "    Writes a complex dictionary to an Excel file.\n",
    "\n",
    "    Parameters:\n",
    "    - data_dict: dict\n",
    "        The dictionary to write to the Excel file. \n",
    "        Each key will be a row with the associated fields as columns.\n",
    "    - file_path: str\n",
    "        The path where the Excel file will be saved.\n",
    "    \"\"\"\n",
    "    # Prepare a list of dictionaries, each representing a row\n",
    "    rows = []\n",
    "    \n",
    "    for character, details in data_dict.items():\n",
    "        # Flatten the details dictionary for each character\n",
    "        row = {'Character': character}\n",
    "        for key, value in details.items():\n",
    "            if isinstance(value, list):\n",
    "                row[key] = ', '.join(map(str, value))  # Join lists into a comma-separated string\n",
    "            else:\n",
    "                row[key] = value\n",
    "        rows.append(row)\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Write the DataFrame to an Excel file\n",
    "    df.to_excel(file_path, index=False)\n",
    "\n",
    "    print(f\"Dictionary has been written to {file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "if CONVERT_TO_PLECO:\n",
    "    fwrite = open(join(DICT_DIR, \"char_dict_pleco.txt\"), \"w\", encoding=\"utf-8\")\n",
    "\n",
    "    try:\n",
    "        with open(join(DATA_DIR, CHAR_DICT_FILE), \"r\", encoding=\"utf-8\") as fread:\n",
    "            char_dict = json.load(fread)\n",
    "    except:\n",
    "        print(f\"No file {CHAR_DICT_FILE}\")\n",
    "        exit()\n",
    "\n",
    "    fwrite.write(\"// Character component dictionary\\n\")\n",
    "\n",
    "    appears_chars = {}\n",
    "\n",
    "    print(f\"Before {len(char_dict)=}\")\n",
    "\n",
    "    new_wordlist = wordset  # | set(char_decompositions.keys())\n",
    "\n",
    "    print(f\"{len(wordset)=}\")\n",
    "    print(f\"{len(char_decompositions)=}\")\n",
    "    print(f\"{len(new_wordlist)=}\")\n",
    "    written = 0\n",
    "\n",
    "    for key in new_wordlist:\n",
    "        if not key or key == \"?\" or key.isdigit() or key not in char_dict:\n",
    "            continue\n",
    "\n",
    "        char = None\n",
    "        components = []\n",
    "        if key in char_dict:\n",
    "            char = char_dict[key]\n",
    "\n",
    "        if key in char_decompositions:\n",
    "            components = regex.findall(PATTERN_ZH, char_decompositions[key])\n",
    "\n",
    "        # if rad_database.is_radical_variant(key):\n",
    "        #     for v in rad_database.get_variants(key):\n",
    "        #         if v not in char_dict:\n",
    "        #             char_dict[v] = char_dict[key]\n",
    "\n",
    "        for comp in components:\n",
    "            if comp.isdigit():\n",
    "                continue\n",
    "\n",
    "            if comp not in appears_chars:\n",
    "                appears_chars[comp] = set([key])\n",
    "            else:\n",
    "                appears_chars[comp].add(key)\n",
    "\n",
    "    print(f\"After {len(char_dict)=}\")\n",
    "\n",
    "    char_info_dict = {}\n",
    "\n",
    "    for key in new_wordlist:\n",
    "        if not key or key == \"?\" or key.isdigit() or key not in char_dict:\n",
    "            continue\n",
    "\n",
    "        char_info = {}    \n",
    "\n",
    "        char = None\n",
    "        components = []\n",
    "\n",
    "        if key in char_dict:\n",
    "            char = char_dict[key]\n",
    "\n",
    "            pinyins = char[\"pinyin\"]\n",
    "            all_meanings = char[\"meaning\"]\n",
    "\n",
    "            char_info.update(char)\n",
    "        else:\n",
    "            pinyin_str = \"\"\n",
    "            try:\n",
    "                pinyin_str = get_pinyin(key)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            pinyins = [pinyin_str]\n",
    "            all_meanings = [[\"(No meaning)\"]]\n",
    "\n",
    "        string = \"\"\n",
    "\n",
    "        decomp_str = \"\"\n",
    "\n",
    "        if char and char[\"tree\"] and key not in char_decompositions and not rad_database.is_radical_variant(key):\n",
    "            char_tree_str = rad_database.norminal(char[\"tree\"]) if len(char[\"tree\"]) == 1 else char[\"tree\"].replace(\"\\n\", \"-\")  # fmt: skip\n",
    "\n",
    "            flog.write(f\"{key}\\t{'Hanzipy YES IDS No'}\\t{hex(ord(key))}\\t{char_tree_str}\\n\")  # fmt: skip\n",
    "\n",
    "        is_rad = rad_database.norminal(key) if rad_database.is_radical_variant(key) else \"\"  # fmt: skip\n",
    "\n",
    "        if char and not char[\"tree\"] and key not in char_decompositions and not rad_database.is_radical_variant(key):  # fmt: skip\n",
    "            flog.write(f\"{key}\\t{'Found no decompositions for'}\\t{is_rad}\\t{hex(ord(key))}\\n\")  # fmt: skip\n",
    "            continue\n",
    "\n",
    "        if key in char_decompositions:\n",
    "            components = list(\n",
    "                dict.fromkeys(regex.findall(PATTERN_ZH, char_decompositions[key]))\n",
    "            )  # Remove duplicates but keep order on insertion\n",
    "        elif rad_database.is_radical_variant(key):\n",
    "            components = [key]\n",
    "        else:\n",
    "            components = []\n",
    "\n",
    "        char_info['components'] = components\n",
    "\n",
    "        if key in char_decompositions:\n",
    "            decomp_str += f\"{pleco_make_bold(pleco_make_dark_gray(PC_DECOMPOSITIONS_MARK))}\\n\"\n",
    "            decomp = key + PC_WIDESPACE + char_decompositions[key].replace(\" \", \"\")\n",
    "\n",
    "            decomp = regex.sub(PATTERN_ZH, make_chinese_blue, decomp)\n",
    "            decomp_str += decomp\n",
    "            decomp_str += \"\\n\"\n",
    "        else:\n",
    "            # print(f\"Found no decompositions for {key}\")\n",
    "            pass\n",
    "\n",
    "        string += f\"{decomp_str}\"\n",
    "\n",
    "        char_tree = \"\"\n",
    "        if char and char[\"tree\"] and char[\"tree\"] != key:\n",
    "            if char[\"tree\"] == key and rad_database.is_radical_variant(key):\n",
    "                char[\"tree\"] = rad_database.norminal(key)\n",
    "\n",
    "                pass\n",
    "\n",
    "            string += f\"{pleco_make_bold(pleco_make_dark_gray(PC_TREE_MARK))}\\n\"\n",
    "            char_tree = char[\"tree\"]\n",
    "\n",
    "            char_tree = regex.sub(r\"(\\d+)\", replace_numbers, char_tree)\n",
    "            char_tree = regex.sub(PATTERN_ZH, replace_chinese_in_tree, char_tree)\n",
    "\n",
    "        char_info['tree'] = char_tree\n",
    "\n",
    "        string += f\"{char_tree}\"\n",
    "\n",
    "        string += \"\\n\"\n",
    "\n",
    "        if key in mnemonics:\n",
    "            string += f\"{pleco_make_bold(pleco_make_dark_gray(PC_MNEMONICS_MARK))}\\n\"\n",
    "\n",
    "            mn_file, others, mn_meaning, mn_mnemonics, mn_chars = mnemonics[key]\n",
    "\n",
    "            mn_meaning = mn_meaning.strip().capitalize()\n",
    "            mn_mnemonics = mn_mnemonics.strip().capitalize()\n",
    "\n",
    "            mn_meaning_str = f\"{pleco_make_italic(mn_meaning)} \" if mn_meaning else \"\"\n",
    "\n",
    "            mn_mnemonics_str = f\"{pleco_make_italic(mn_meaning_str)}{mn_mnemonics} {mn_chars}\\n\"\n",
    "            mn_mnemonics_str = regex.sub(PATTERN_ZH, replace_chinese_blue, mn_mnemonics_str)\n",
    "\n",
    "            string += mn_mnemonics_str\n",
    "\n",
    "            char_info['mnemonics'] = mn_mnemonics\n",
    "            char_info['meaning'] = mn_meaning[0] if len(mn_meaning) else []\n",
    "            char_info['appears_in'] = mn_chars\n",
    "\n",
    "        if components and components[0] != key:\n",
    "            string += f\"{pleco_make_bold(pleco_make_dark_gray(PC_COMPONENTS_MARK))}\\n\"\n",
    "\n",
    "            for comp in components:\n",
    "                if key == comp:\n",
    "                    continue\n",
    "\n",
    "                if comp not in char_dict and not rad_database.is_radical_variant(comp):\n",
    "                    # flog.write(f\"{comp}\\tNot in char_dict\\n\")\n",
    "                    # print(f\"{comp}\\tNot in char_dict\")\n",
    "                    continue\n",
    "\n",
    "                meaning_text = \"\"\n",
    "\n",
    "                comp_char = comp\n",
    "\n",
    "                if rad_database.is_radical_variant(comp):\n",
    "                    comp_char = rad_database.norminal(comp)\n",
    "                    item = rad_database.lookup(comp)\n",
    "                    pinyin = item[\"pinyin\"]\n",
    "                    meaning_text = item[\"meaning\"]\n",
    "                    variants = sorted(rad_database.get_variants(comp))\n",
    "\n",
    "                    if key in variants:  # If same as key headword, remove\n",
    "                        variants.remove(key)\n",
    "\n",
    "                    alternatives = \"Alternative(s): \" + PC_MIDDLE_DOT.join(variants) if variants else \"\"  # fmt: skip\n",
    "                    alternatives = regex.sub(PATTERN_ZH, replace_chinese_blue, alternatives)\n",
    "\n",
    "                    extra_meaning = f\". Radical #{item['number']}. {alternatives}\"\n",
    "\n",
    "                    meaning_text = meaning_text.strip() + extra_meaning\n",
    "                elif comp in char_dict:\n",
    "                    pinyin = char_dict[comp][\"pinyin\"][0]\n",
    "                    meaning_text = \"\"\n",
    "                    for num, com_meaning in enumerate(char_dict[comp][\"meaning\"][0]):\n",
    "                        meaning_text += f\"{number_in_cirle(num+1)} {com_meaning} \"\n",
    "\n",
    "                string += f\"{pleco_make_link(comp_char)} {pleco_make_italic(pinyin)} {meaning_text}\\n\"\n",
    "\n",
    "        if key in appears_chars and (contains := sort_by_freq(appears_chars[key])):\n",
    "            if key in contains:\n",
    "                contains.remove(key)\n",
    "\n",
    "            if contains:\n",
    "                blue_chars = [pleco_make_link(char) for char in contains[:MAX_APPEARANCES]]\n",
    "                appear_str = f\"{pleco_make_bold(pleco_make_dark_gray(PC_APPEARS_MARK))} {len(contains)}\"\n",
    "                string += f\"{pleco_make_dark_gray(appear_str)}\\n\"\n",
    "\n",
    "                string += f\"{PC_MIDDLE_DOT.join(blue_chars)}\"\n",
    "\n",
    "        string = regex.sub(PATTERN_PY, replace_num_pinyin, string)\n",
    "\n",
    "        # Each pronunctiation and meaning need a separate line\n",
    "        for num, pinyin in enumerate(pinyins):\n",
    "            meanings = all_meanings[num]\n",
    "\n",
    "            main_string = f\"{key}\\t{pinyin}\\t\"\n",
    "            main_string += f\"{pleco_make_bold(pleco_make_dark_gray(PC_MEANING_MARK))}\\n\"\n",
    "\n",
    "            for num, meaning in enumerate(meanings):\n",
    "                main_string += f\"{number_in_cirle(num+1)} {meaning} \"\n",
    "\n",
    "            main_string += \"\\n\"\n",
    "\n",
    "            main_string += string\n",
    "\n",
    "            main_string = main_string.replace(\"\\n\", PC_NEW_LINE)\n",
    "            # print(string)\n",
    "            fwrite.write(f\"{main_string}\\n\")\n",
    "            written += 1\n",
    "\n",
    "        char_info_dict[key] = char_info\n",
    "\n",
    "        pass\n",
    "\n",
    "    fwrite.close()\n",
    "\n",
    "complex_dict_to_excel(char_info_dict, 'char_dict.xlsx')\n",
    "\n",
    "char_dict_keys = frozenset(char_dict.keys())\n",
    "\n",
    "print(f\"{written=}\")\n",
    "\n",
    "print(f\"In wordset but not in final list: {len(wordset - char_dict_keys)}\")\n",
    "print(f\"Not in wordset (new components): {len(char_dict_keys - wordset)}\")\n",
    "\n",
    "end_datetime = datetime.datetime.now()\n",
    "\n",
    "print(end_datetime - start_datetime)\n",
    "flog.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8844"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_wordlist - mnemonics_words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4018"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnemonics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnemonics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tudien",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
