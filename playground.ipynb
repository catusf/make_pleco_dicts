{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "泪 components:\n",
      "\n",
      "氵: ['\"water\" radical in Chinese characters (Kangxi radical 85), occurring in 没, 法, 流 etc', 'see also 三點水|三点水[san1 dian3 shui3]']\n",
      "目: ['eye', 'item', 'section', 'list', 'catalogue', 'table of contents', 'order (taxonomy)', 'goal', 'name', 'title']\n",
      "\n",
      "Translations for 发:\n",
      "\n",
      "fa1 ['to send out', \"to show (one's feeling)\", 'to issue', 'to develop', 'to make a bundle of money', 'classifier for gunshots (rounds)']\n",
      "fa4 ['hair', 'Taiwan pr. [fa3]']\n"
     ]
    }
   ],
   "source": [
    "from chin_dict.chindict import ChinDict\n",
    "\n",
    "cd = ChinDict()\n",
    "\n",
    "char_result = cd.lookup_char(\"泪\")\n",
    "\n",
    "print()\n",
    "print(\"泪 components:\")\n",
    "print()\n",
    "\n",
    "for component in char_result.components:\n",
    "\tprint(component.character + \":\", component.meaning)\n",
    "\n",
    "# 氵: ['\"water\" radical in Chinese characters (Kangxi radical 85), occurring in 没, 法, 流 etc', 'see also 三點水|三点水[san1 dian3 shui3]']\n",
    "# 目: ['eye', 'item', 'section', 'list', 'catalogue', 'table of contents', 'order (taxonomy)', 'goal', 'name', 'title']\n",
    "\n",
    "print()\n",
    "\n",
    "word_result = cd.lookup_word(\"发\")\n",
    "\n",
    "print(\"Translations for 发:\")\n",
    "print()\n",
    "for word in word_result:\n",
    "\tprint(f'{word.pinyin} {word.meaning}')\n",
    "\n",
    "# Simplified: 发\n",
    "# Traditional: 發\n",
    "# Pinyin: fa1\n",
    "# Meaning: ['to send out', \"to show (one's feeling)\", 'to issue', 'to develop', 'to make a bundle of money', 'classifier for gunshots (rounds)']\n",
    "\n",
    "# Simplified: 发\n",
    "# Traditional: 髮\n",
    "# Pinyin: fa4\n",
    "# Meaning: ['hair', 'Taiwan pr. [fa3]']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(wordset)=7873\n",
      "○ has no components:\n",
      "〇 has no components:\n",
      "㗎 has no components:\n",
      "一 has no components:\n"
     ]
    }
   ],
   "source": [
    "from chin_dict.chindict import ChinDict\n",
    "\n",
    "PC_NEW_LINE = chr(0xEAB1)\n",
    "PC_HANVIET_MARK = \"HÁN VIỆT\"\n",
    "PC_RELATED_MARK = \"LIÊN QUAN\"\n",
    "PC_VIDU_OLD_MARK = \"Ví dụ:\"\n",
    "PC_VIDU_NEW_MARK = \"VÍ DỤ\"\n",
    "PC_DIAMOND = \"❖\"\n",
    "PC_ARROW = \"»\"\n",
    "PC_TRIANGLE = \"▶\"  # ►\n",
    "PC_DIAMOND_SUIT = \"♦\"\n",
    "PC_HEART_SUIT = \"♥\"\n",
    "PC_CLUB_SUIT = \"♣\"\n",
    "PC_SPADE_SUIT = \"♠\"\n",
    "\n",
    "cd = ChinDict()\n",
    "\n",
    "wordset = set()\n",
    "\n",
    "with open('dic_words_set.txt', 'r', encoding='utf-8') as fread:\n",
    "    wordset.update(fread.read())\n",
    "\n",
    "print(f'{len(wordset)=}')\n",
    "\n",
    "wordlist = sorted(list(wordset))\n",
    "import hanzidentifier\n",
    "\n",
    "fwrite = open('char_info_dict.txt', 'w', encoding='utf-8')\n",
    "for word in wordlist[:50]:\n",
    "    if not hanzidentifier.is_simplified(word):\n",
    "        continue\n",
    "    \n",
    "    string = ''\n",
    "\n",
    "    char_result = cd.lookup_char(word)\n",
    "    if hasattr(char_result, 'components'):\n",
    "        pinyin = char_result.pinyin[-1]\n",
    "        string += f\"{word}\\t{pinyin}\\t{'/'.join(char_result.meaning)}\\n{text if text else ''}\\n\"\n",
    "        # print(f\"{word} {pinyin} meaning: {'/'.join(char_result.meaning)}\\n{text if text else ''}\")\n",
    "\n",
    "        tree = char_result.tree(show=False)\n",
    "        if tree:\n",
    "            string += f'{tree}\\n'\n",
    "\n",
    "        for component in char_result.components:\n",
    "            # print(f'\\tcomponent  : {component.character} {\"/\".join(component.meaning) if component.meaning else \"(No meaning)\"}')\n",
    "            string += f'  {component.character} {\"/\".join(component.meaning) if component.meaning else \"(No meaning)\"}'\n",
    "        print(string)\n",
    "        string = string.replace('\\n', PC_NEW_LINE)\n",
    "        fwrite.write(f'{string}\\n')\n",
    "    else:\n",
    "        print(f\"{word} has no components:\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwrite.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['举', '㐄', '丨', '二', '兴', '㇇']\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "\n",
    "# pattern = re.compile(r'([\\p{IsHan}\\p{IsBopo}\\p{IsHira}\\p{IsKatakana}]+)', re.UNICODE)\n",
    "\n",
    "pattern = re.compile(r'([\\p{Block=CJK_Compatibility}\\p{Block=CJK_Compatibility_Forms}\\p{Block=CJK_Compatibility_Ideographs}\\p{Block=CJK_Compatibility_Ideographs_Supplement}\\p{Block=CJK_Radicals_Supplement}\\p{Block=CJK_Strokes}\\p{Block=CJK_Symbols_And_Punctuation}\\p{Block=CJK_Unified_Ideographs}\\p{Block=CJK_Unified_Ideographs_Extension_A}\\p{Block=CJK_Unified_Ideographs_Extension_B}\\p{Block=CJK_Unified_Ideographs_Extension_C}\\p{Block=CJK_Unified_Ideographs_Extension_D}\\p{Block=CJK_Unified_Ideographs_Extension_E}\\p{Block=CJK_Unified_Ideographs_Extension_F}\\p{Block=Enclosed_CJK_Letters_And_Months}]+)', re.UNICODE)\n",
    "\n",
    "\n",
    "input = '''举\n",
    "├── 㐄 (2)\n",
    "│   ├── 丨 (3)\n",
    "│   └── 二 (4)\n",
    "└── 兴 (1)\n",
    "CharResult(㇇)'''\n",
    "\n",
    "matches = re.findall(pattern, input)\n",
    "\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "try:\n",
    "    with open('char_dict.json', \"r\", encoding=\"utf-8\") as fread:\n",
    "        char_dict = json.load(fread)\n",
    "except:\n",
    "    print(f'No file {'char_dict.json'}')\n",
    "\n",
    "wordset = set()\n",
    "\n",
    "with open('dic_words_set.txt', 'r', encoding='utf-8') as fread:\n",
    "    wordset.update(fread.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wordset)\n",
    "char_dict_set = set(list(char_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n',\n",
       " '○',\n",
       " '〇',\n",
       " '㗎',\n",
       " '倣',\n",
       " '傢',\n",
       " '僊',\n",
       " '儁',\n",
       " '兎',\n",
       " '兕',\n",
       " '勅',\n",
       " '勩',\n",
       " '匟',\n",
       " '厤',\n",
       " '叡',\n",
       " '呪',\n",
       " '咲',\n",
       " '唕',\n",
       " '唸',\n",
       " '啓',\n",
       " '啗',\n",
       " '喆',\n",
       " '喎',\n",
       " '喒',\n",
       " '嗰',\n",
       " '噉',\n",
       " '嚮',\n",
       " '囓',\n",
       " '坵',\n",
       " '埜',\n",
       " '堃',\n",
       " '塼',\n",
       " '塿',\n",
       " '墠',\n",
       " '壈',\n",
       " '壻',\n",
       " '妬',\n",
       " '姙',\n",
       " '媿',\n",
       " '嫺',\n",
       " '嬃',\n",
       " '嬭',\n",
       " '嬾',\n",
       " '孻',\n",
       " '寃',\n",
       " '尅',\n",
       " '尟',\n",
       " '廐',\n",
       " '廼',\n",
       " '彄',\n",
       " '恠',\n",
       " '愬',\n",
       " '慴',\n",
       " '憖',\n",
       " '懃',\n",
       " '懽',\n",
       " '戹',\n",
       " '扞',\n",
       " '拏',\n",
       " '掽',\n",
       " '搆',\n",
       " '搤',\n",
       " '搥',\n",
       " '搾',\n",
       " '撦',\n",
       " '擕',\n",
       " '擧',\n",
       " '攩',\n",
       " '攷',\n",
       " '敺',\n",
       " '斲',\n",
       " '昇',\n",
       " '曏',\n",
       " '柟',\n",
       " '椗',\n",
       " '椷',\n",
       " '楥',\n",
       " '榘',\n",
       " '槼',\n",
       " '樑',\n",
       " '橤',\n",
       " '毘',\n",
       " '汎',\n",
       " '洩',\n",
       " '溼',\n",
       " '澁',\n",
       " '澂',\n",
       " '澣',\n",
       " '濆',\n",
       " '灨',\n",
       " '煖',\n",
       " '燄',\n",
       " '燐',\n",
       " '燖',\n",
       " '燻',\n",
       " '牀',\n",
       " '牋',\n",
       " '牓',\n",
       " '犇',\n",
       " '獧',\n",
       " '玁',\n",
       " '玅',\n",
       " '瑲',\n",
       " '璊',\n",
       " '璫',\n",
       " '璿',\n",
       " '甎',\n",
       " '甖',\n",
       " '畊',\n",
       " '疎',\n",
       " '疘',\n",
       " '疿',\n",
       " '皙',\n",
       " '皜',\n",
       " '睍',\n",
       " '瞖',\n",
       " '矙',\n",
       " '砦',\n",
       " '硜',\n",
       " '碁',\n",
       " '碪',\n",
       " '磠',\n",
       " '祕',\n",
       " '秊',\n",
       " '秪',\n",
       " '稬',\n",
       " '穇',\n",
       " '穉',\n",
       " '穤',\n",
       " '穨',\n",
       " '窵',\n",
       " '竈',\n",
       " '筴',\n",
       " '箒',\n",
       " '箠',\n",
       " '篘',\n",
       " '簑',\n",
       " '籔',\n",
       " '粧',\n",
       " '紃',\n",
       " '紬',\n",
       " '絅',\n",
       " '絏',\n",
       " '絪',\n",
       " '絰',\n",
       " '絺',\n",
       " '綌',\n",
       " '綪',\n",
       " '綯',\n",
       " '縕',\n",
       " '繖',\n",
       " '繻',\n",
       " '纁',\n",
       " '纆',\n",
       " '纇',\n",
       " '缾',\n",
       " '罋',\n",
       " '羣',\n",
       " '翫',\n",
       " '翽',\n",
       " '肧',\n",
       " '臈',\n",
       " '臙',\n",
       " '臝',\n",
       " '艣',\n",
       " '艸',\n",
       " '菓',\n",
       " '菴',\n",
       " '蓆',\n",
       " '蔆',\n",
       " '蔕',\n",
       " '蕋',\n",
       " '薀',\n",
       " '薘',\n",
       " '藭',\n",
       " '藷',\n",
       " '蘀',\n",
       " '蘤',\n",
       " '虆',\n",
       " '蚘',\n",
       " '蜋',\n",
       " '蜨',\n",
       " '蜺',\n",
       " '蝀',\n",
       " '蝡',\n",
       " '蠁',\n",
       " '蠙',\n",
       " '衺',\n",
       " '袴',\n",
       " '襏',\n",
       " '襬',\n",
       " '覊',\n",
       " '覩',\n",
       " '觕',\n",
       " '訏',\n",
       " '訒',\n",
       " '詗',\n",
       " '説',\n",
       " '諟',\n",
       " '謏',\n",
       " '譆',\n",
       " '譸',\n",
       " '讅',\n",
       " '讙',\n",
       " '豔',\n",
       " '賛',\n",
       " '賵',\n",
       " '赬',\n",
       " '跴',\n",
       " '蹻',\n",
       " '躭',\n",
       " '軏',\n",
       " '輈',\n",
       " '輗',\n",
       " '輭',\n",
       " '輮',\n",
       " '輶',\n",
       " '迺',\n",
       " '遯',\n",
       " '酇',\n",
       " '醲',\n",
       " '醼',\n",
       " '釬',\n",
       " '鈇',\n",
       " '鉥',\n",
       " '鉶',\n",
       " '鋙',\n",
       " '錞',\n",
       " '鍫',\n",
       " '鎌',\n",
       " '鎗',\n",
       " '鎚',\n",
       " '鐏',\n",
       " '鐶',\n",
       " '鑕',\n",
       " '鑛',\n",
       " '鑤',\n",
       " '鑪',\n",
       " '鑱',\n",
       " '鑵',\n",
       " '闉',\n",
       " '闑',\n",
       " '闒',\n",
       " '闚',\n",
       " '闠',\n",
       " '闤',\n",
       " '阬',\n",
       " '隤',\n",
       " '隷',\n",
       " '鞀',\n",
       " '鞾',\n",
       " '韍',\n",
       " '頫',\n",
       " '顋',\n",
       " '颸',\n",
       " '飣',\n",
       " '飥',\n",
       " '餖',\n",
       " '餗',\n",
       " '餚',\n",
       " '餧',\n",
       " '饘',\n",
       " '饟',\n",
       " '馹',\n",
       " '駉',\n",
       " '騂',\n",
       " '騣',\n",
       " '騧',\n",
       " '驩',\n",
       " '骾',\n",
       " '魨',\n",
       " '鮀',\n",
       " '鮆',\n",
       " '鮓',\n",
       " '鮠',\n",
       " '鰜',\n",
       " '鱠',\n",
       " '鱨',\n",
       " '鱻',\n",
       " '鳲',\n",
       " '鴈',\n",
       " '鵷',\n",
       " '鶊',\n",
       " '鶡',\n",
       " '鶬',\n",
       " '鶹',\n",
       " '鷁',\n",
       " '鷟',\n",
       " '鷫',\n",
       " '鸂',\n",
       " '鸇',\n",
       " '鸑',\n",
       " '麤',\n",
       " '黶',\n",
       " '鼃',\n",
       " '鼇',\n",
       " '鼈',\n",
       " '齕',\n",
       " '齗',\n",
       " '齩',\n",
       " '齮',\n",
       " '龢',\n",
       " '１',\n",
       " '５'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordset - char_dict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chin_dict.chindict import ChinDict\n",
    "\n",
    "cd = ChinDict()\n",
    "c = cd.lookup_char( '龢')\n",
    "\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERN_ZH = r'([\\p{Block=CJK_Unified_Ideographs}\\p{Block=CJK_Compatibility}\\p{Block=CJK_Compatibility_Forms}\\p{Block=CJK_Compatibility_Ideographs}\\p{Block=CJK_Compatibility_Ideographs_Supplement}\\p{Block=CJK_Radicals_Supplement}\\p{Block=CJK_Strokes}\\p{Block=CJK_Symbols_And_Punctuation}\\p{Block=CJK_Unified_Ideographs}\\p{Block=CJK_Unified_Ideographs_Extension_A}\\p{Block=CJK_Unified_Ideographs_Extension_B}\\p{Block=CJK_Unified_Ideographs_Extension_C}\\p{Block=CJK_Unified_Ideographs_Extension_D}\\p{Block=CJK_Unified_Ideographs_Extension_E}\\p{Block=CJK_Unified_Ideographs_Extension_F}\\p{Block=Enclosed_CJK_Letters_And_Months}])'\n",
    "PATTERN_ZH1 = r'([\\p{Block=CJK_Unified_Ideographs}\\p{Block=CJK_Compatibility}\\p{Block=CJK_Compatibility_Forms}' \\\n",
    "    r'\\p{Block=CJK_Compatibility_Ideographs}\\p{Block=CJK_Compatibility_Ideographs_Supplement}' \\\n",
    "    r'\\p{Block=CJK_Radicals_Supplement}\\p{Block=CJK_Strokes}\\p{Block=CJK_Symbols_And_Punctuation}' \\\n",
    "    r'\\p{Block=CJK_Unified_Ideographs}\\p{Block=CJK_Unified_Ideographs_Extension_A}' \\\n",
    "    r'\\p{Block=CJK_Unified_Ideographs_Extension_B}\\p{Block=CJK_Unified_Ideographs_Extension_C}'\\\n",
    "    r'\\p{Block=CJK_Unified_Ideographs_Extension_D}\\p{Block=CJK_Unified_Ideographs_Extension_E}' \\\n",
    "    r'\\p{Block=CJK_Unified_Ideographs_Extension_F}\\p{Block=Enclosed_CJK_Letters_And_Months}])'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATTERN_ZH==PATTERN_ZH1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "podcast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
