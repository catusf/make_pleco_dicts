{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1: html\\10来.html...\n",
      "Processing 2: html\\2012来.html...\n",
      "Processing 3: html\\20来.html...\n",
      "Processing 4: html\\〇.html...\n",
      "Processing 5: html\\一.html...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\it.fsoft\\OneDrive - FPT Software\\Personal\\Playground\\extract_hanzii\\extract.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/it.fsoft/OneDrive%20-%20FPT%20Software/Personal/Playground/extract_hanzii/extract.ipynb#W0sZmlsZQ%3D%3D?line=148'>149</a>\u001b[0m pleco_string \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpc_make_blue(mean_chinese)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mmean_viet\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mPC_NEW_LINE\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mPC_NEW_LINE\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/it.fsoft/OneDrive%20-%20FPT%20Software/Personal/Playground/extract_hanzii/extract.ipynb#W0sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m (example_s \u001b[39m:=\u001b[39m definition\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m\"\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbox-example\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/it.fsoft/OneDrive%20-%20FPT%20Software/Personal/Playground/extract_hanzii/extract.ipynb#W0sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m     example_chinese \u001b[39m=\u001b[39m example_s\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mp\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mex-word\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mtext\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/it.fsoft/OneDrive%20-%20FPT%20Software/Personal/Playground/extract_hanzii/extract.ipynb#W0sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m     example_chinese \u001b[39m=\u001b[39m remove_traditional_text(example_chinese)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/it.fsoft/OneDrive%20-%20FPT%20Software/Personal/Playground/extract_hanzii/extract.ipynb#W0sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m     example_pron \u001b[39m=\u001b[39m example_s\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mp\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mex-phonetic\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mtext\n",
      "\u001b[1;32mc:\\Users\\it.fsoft\\OneDrive - FPT Software\\Personal\\Playground\\extract_hanzii\\extract.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/it.fsoft/OneDrive%20-%20FPT%20Software/Personal/Playground/extract_hanzii/extract.ipynb#W0sZmlsZQ%3D%3D?line=148'>149</a>\u001b[0m pleco_string \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpc_make_blue(mean_chinese)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mmean_viet\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mPC_NEW_LINE\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mPC_NEW_LINE\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/it.fsoft/OneDrive%20-%20FPT%20Software/Personal/Playground/extract_hanzii/extract.ipynb#W0sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m (example_s \u001b[39m:=\u001b[39m definition\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m\"\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbox-example\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/it.fsoft/OneDrive%20-%20FPT%20Software/Personal/Playground/extract_hanzii/extract.ipynb#W0sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m     example_chinese \u001b[39m=\u001b[39m example_s\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mp\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mex-word\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mtext\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/it.fsoft/OneDrive%20-%20FPT%20Software/Personal/Playground/extract_hanzii/extract.ipynb#W0sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m     example_chinese \u001b[39m=\u001b[39m remove_traditional_text(example_chinese)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/it.fsoft/OneDrive%20-%20FPT%20Software/Personal/Playground/extract_hanzii/extract.ipynb#W0sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m     example_pron \u001b[39m=\u001b[39m example_s\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mp\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mex-phonetic\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mtext\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python311\\envs\\podcast\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\envs\\podcast\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import glob\n",
    "import json\n",
    "from pinyin import get as pinyinget \n",
    "\n",
    "from tools_configs import *\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_chinese_bracket(text):\n",
    "    return re.sub('【(.+?)】', r'\\1', text)\n",
    "\n",
    "def remove_traditional_text(text):\n",
    "    return re.sub('【.+?】', '', text)\n",
    "\n",
    "def remove_see_more_examples(text):\n",
    "    return re.sub('Xem thêm \\d+ ví dụ nữa', '', text)\n",
    "\n",
    "with open(TOP_WORDS_24K, 'r', encoding='utf-8') as fin:\n",
    "    top_words_24k = set(json.load(fin))\n",
    "\n",
    "import re\n",
    "NORMAL = r'([^\t↑ ,; 0-9a-zA-Z()一-龥])'\n",
    "\n",
    "PC_DICT_NAME = '//Trung-Viet Dict'\n",
    "\n",
    "PC_NEW_LINE = chr(0xEAB1)\n",
    "PC_HANVIET_MARK = 'HÁN VIỆT'\n",
    "PC_GOIY_MARK = 'GỢI Ý'\n",
    "PC_VIDU_OLD_MARK = 'Ví dụ:'\n",
    "PC_VIDU_NEW_MARK = 'VÍ DỤ'\n",
    "PC_DIAMOND = '❖'\n",
    "PC_ARROW = '»'\n",
    "\n",
    "def pc_make_bold(text):\n",
    "    return f'{chr(0xEAB2)}{text}{chr(0xEAB3)}'\n",
    "\n",
    "def pc_make_blue(text):\n",
    "    # return f'{chr(0xEAC1)}{text}{chr(0xEAC2)}'\n",
    "    return text\n",
    "\n",
    "def pc_make_grey(text):\n",
    "    # return f'{chr(0x3C8F)}{text}{chr(0xEAC2)}'\n",
    "    return text\n",
    "\n",
    "def pc_make_italic(text):\n",
    "    return f'{chr(0xEAB4)}{text}{chr(0xEAB5)}'\n",
    "\n",
    "def pc_make_link(text):\n",
    "    return f'{chr(0xEAB8)}{text}{chr(0xEABB)}'\n",
    "\n",
    "files = glob.glob(f'{HTML_FOLDER}/人*.html')\n",
    "files = glob.glob(f'{HTML_FOLDER}/*.html')\n",
    "\n",
    "# files = glob.glob(f'{HTML_FOLDER}/人面.html')\n",
    "filepath = f'{HTML_FOLDER}/点.html'\n",
    "filepath = f'{HTML_FOLDER}/詗.html'\n",
    "filepath = f'{HTML_FOLDER}/人.html'\n",
    "\n",
    "pleco_string_list = []\n",
    "pleco_string_list.append(f'{PC_DICT_NAME}\\n')\n",
    "\n",
    "MAX_ITEMS = 100 # 20\n",
    "\n",
    "log_file = open('loglig.txt', 'w', encoding='utf-8')\n",
    "\n",
    "for num, filepath in enumerate(files):\n",
    "    \n",
    "    # if filepath != 'html\\一万.html':\n",
    "    #     continue\n",
    "\n",
    "    if num >= MAX_ITEMS:\n",
    "        break\n",
    "    \n",
    "    print(f'Processing {num+1}: {filepath}...')\n",
    "    pleco_string = ''\n",
    "\n",
    "    headword, ext = os.path.splitext(os.path.split(filepath)[1])\n",
    "    # filename = f'{HTML_FOLDER}/{headword}.html'\n",
    "\n",
    "    if headword not in top_words_24k and headword:\n",
    "        continue\n",
    "\n",
    "    url = headword_to_url(headword)\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as fin:\n",
    "        html = fin.read()\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "\n",
    "    content_result = soup.find(\"div\", class_=\"content-result\")\n",
    "\n",
    "    goiy, chitiettu, tukhoahot = list(content_result.next.children)\n",
    "\n",
    "    # Process Chi tiết từ\n",
    "    if not (char_pron := chitiettu.find(\"div\", class_=\"box-word\")):\n",
    "        print(f'{filepath=} has no character pronunciation')\n",
    "        log_file.write(f'No pronunciation\\t{filepath}\\n')\n",
    "\n",
    "        continue\n",
    "    \n",
    "    chinese = '' if not (chinese_s := char_pron.find('span', class_='simple-tradition-wrap')) else remove_traditional_text(chinese_s.text)\n",
    "\n",
    "    pinyin = '' if not (pinyin_s := char_pron.find('span', class_='txt-pinyin')) else pinyin_s.text[1:-1].lower()\n",
    "    \n",
    "    viet = '' if not (viet_s := char_pron.find('span', class_='txt-cn_vi')) else viet_s.text[1:-1].lower()\n",
    "\n",
    "    if not chinese_s:\n",
    "        log_file.write(f'No Chinese characters\\t{filepath}\\n')\n",
    "\n",
    "    pleco_string += f'{chinese}\\t{pinyin}\\t'\n",
    "\n",
    "    if viet:\n",
    "        pleco_string += f'{pc_make_bold(PC_HANVIET_MARK)} {viet}{PC_NEW_LINE}' \n",
    "\n",
    "    # print(f'{chinese=} {pinyin=} {viet=}')\n",
    "\n",
    "    tuloai_list = [item.text.strip() for item in chitiettu.find_all(\"span\", class_=\"word-kind\")]\n",
    "\n",
    "    for tuloai in chitiettu.find_all(\"div\", class_=\"box-content\"): \n",
    "        tuloai_text_s = tuloai.find('div', class_=\"kind-word\")\n",
    "        \n",
    "        if tuloai_text_s:\n",
    "            tuloai_text = tuloai.div.text.strip()\n",
    "        else:\n",
    "            tuloai_text = '/'.join(tuloai_list)\n",
    "        \n",
    "        tuloai_text = tuloai_text.upper()\n",
    "\n",
    "        pleco_string += f'{PC_DIAMOND} {pc_make_grey(pc_make_bold(tuloai_text))}{PC_NEW_LINE}'\n",
    "        # print(f'## {tuloai_text}')\n",
    "\n",
    "        definitions = tuloai.find_all(\"div\", class_=\"item-content\")\n",
    "\n",
    "        for num, definition in enumerate(definitions):\n",
    "            # print(definition.text)\n",
    "\n",
    "            number = definition.find(\"div\", class_=\"icon-dot\").text\n",
    "            # mean = definition.find(\"div\", class_=\"box-mean\").text.replace('\\n', ' ')\n",
    "            mean_viet = definition.find(\"span\", class_=\"simple-tradition-wrap\").text.replace('\\n', ' ')\n",
    "            \n",
    "            mean_chinese = '' if not (mean_chinese_s := definition.find(\"div\", class_=\"txt-mean-explain\")) else mean_chinese_s.text\n",
    "    \n",
    "            if not mean_chinese_s:\n",
    "                log_file.write(f'No Chinese meening\\t{filepath}\\n')\n",
    "\n",
    "            pleco_string += pc_make_bold(str(num+1)) + ' ' \n",
    "            pleco_string += f'{pc_make_blue(mean_chinese)} {mean_viet}{PC_NEW_LINE}{PC_NEW_LINE}'\n",
    "\n",
    "            if (example_s := definition.find(\"div\", class_=\"box-example\")):\n",
    "                example_chinese = example_s.find('p', class_='ex-word').text\n",
    "                example_chinese = remove_traditional_text(example_chinese)\n",
    "\n",
    "                example_pron = example_s.find('p', class_='ex-phonetic').text\n",
    "                example_meaning = example_s.find('p', class_='ex-mean').text\n",
    "                \n",
    "                pleco_string += f'{pc_make_bold(PC_VIDU_NEW_MARK)}{PC_NEW_LINE} '\n",
    "                pleco_string += f'{pc_make_bold(example_chinese)} {pc_make_italic(example_pron)} {example_meaning}{PC_NEW_LINE}{PC_NEW_LINE}'\n",
    "                \n",
    "            # print(f'{mean_viet=} {mean_chinese=} {example=}')\n",
    "\n",
    "    recommendations = goiy.find_all(\"div\", class_=\"box-item\")\n",
    "    pleco_string += f'{pc_make_bold(PC_GOIY_MARK)}{PC_NEW_LINE}'\n",
    "\n",
    "    for recommendation in recommendations:\n",
    "        # print(recommendation.text)\n",
    "\n",
    "        rec_mean = recommendation.find('div', class_=\"box-mean\").text.replace('\\n', ' ')\n",
    "        \n",
    "        rec_chinese = remove_traditional_text(recommendation.find('span', class_=\"simple-tradition-wrap\").text).replace('\\n', ' ')\n",
    "        \n",
    "        rec_pinyin = pinyinget(rec_chinese) if not (rec_pinyin_s := recommendation.find('div', class_=\"txt-pinyin\")) else remove_chinese_bracket(recommendation.find('div', class_=\"txt-pinyin\").text).lower()\n",
    "\n",
    "        pleco_string += f'{PC_ARROW} {pc_make_bold(rec_chinese)} {pc_make_italic(rec_pinyin)} {rec_mean}{PC_NEW_LINE}{PC_NEW_LINE}'\n",
    "        # print(f'{rec_mean=} {rec_pinyin=} {rec_chinese=}')\n",
    "\n",
    "    pleco_string = pleco_string.replace('\\n', PC_NEW_LINE)\n",
    "\n",
    "    pleco_string_list.append(f'{pleco_string}\\n')\n",
    "\n",
    "log_file.close()\n",
    "\n",
    "with open('hanzii_pleco.txt', 'w', encoding='utf-8') as fout:\n",
    "    fout.writelines(pleco_string_list)\n",
    "\n",
    "print(''.join(pleco_string_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(点儿) 液体的小滴\n"
     ]
    }
   ],
   "source": [
    "print(remove_traditional_text('(点儿) 液体的小滴【(點兒)液體的小滴】', ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(點兒)液體的小滴'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_chinese_bracket('【(點兒)液體的小滴】')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Danh từ '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chitiettu.find_all(\"div\", class_=\"slider-content\")[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "'''\n",
    "https://plecoforums.com/threads/multiple-new-lines-in-user-defined-flashcards.5916/#post-44863\n",
    "\n",
    "|2756| Diamond\n",
    "EAB1 = new line\n",
    "EAB2/EAB3 = bold\n",
    "EAB4/EAB5 = italic\n",
    "EAB8/EABB = \"copy-whatever's-in-this-to-the-Input-Field hyperlinks\"\n",
    "coloured text:\n",
    "\"EAC1 followed by two characters with the highest-order bit 1 and the lowest-order 12 bits representing the first/second halves of a 24-bit RGB color value to start the range, EAC2 to end. So to render a character in green, for example, you'd want EAC1 800F 8F00, then the character, then EAC2.\"\n",
    "---\n",
    "UTF-8: U+EAB1 = '\\xee\\xaa\\xb1'\n",
    "\n",
    "\n",
    "EAB2/EAB3 = bold\n",
    "EAB4/EAB5 = italic\n",
    "\n",
    "eabe ... eabf: Bold\n",
    "eab8 ... eabb|: Hyperlink\n",
    "\n",
    "一\t\tone |2756| floor; ceiling|eab1| |eab1||eabe|PINYIN|eabf| y|12b||eab1| |eab1||eabe|FRAME|eabf| 1, |eabe|LESSON|eabf| 1, |eabe|BOOK|eabf| 1, |eabe|PAGE|eabf|  19|eab1| |eab1||eabe|NAVIGATION|eabf| ↑Lesson 1↑ (|eab8|本书1第1课|eabb|) |bb|two|bb| (|eab8|二|eabb|)|eab1| |eab1||eabe|SUBTLEX|eabf| |eab8|一|eabb|, |eab8|一个|eabb|, |eab8|一起|eabb|, |eab8|一样|eabb|, |eab8|一下|eabb|, |eab8|一直|eabb|, |eab8|一切|eabb|, |eab8|一点|eabb|, |eab8|一定|eabb|, |eab8|第一|eabb|, |eab8|一些|eabb|, |eab8|唯一|eabb|, |eab8|一会儿|eabb|, |eab8|一旦|eabb|, |eab8|之一|eabb|, |eab8|一半|eabb|, |eab8|一边|eabb|, |eab8|一般|eabb|, |eab8|一生|eabb|, |eab8|一刻|eabb|, |eab8|一辈子|eabb|, |eab8|一一|eabb|, |eab8|一致|eabb|, |eab8|一会|eabb|, |eab8|一路|eabb|, |eab8|万一|eabb|, |eab8|一分|eabb|, |eab8|一点儿|eabb|, |eab8|一团糟|eabb|, |eab8|一整天|eabb|, |eab8|一面|eabb|, |eab8|一百|eabb|, |eab8|一无所知|eabb|, |eab8|一两|eabb|, |eab8|进一步|eabb|, |eab8|一家|eabb|, |eab8|一百万|eabb|, |eab8|一时|eabb|, |eab8|一千|eabb|, |eab8|一模一样|eabb|, |eab8|一阵子|eabb|, |eab8|一向|eabb|, |eab8|一共|eabb|, |eab8|一阵|eabb|, |eab8|同一个|eabb|, |eab8|一万|eabb|, |eab8|一番|eabb|, |eab8|以防万一|eabb|, |eab8|一下子|eabb|, |eab8|星期一|eabb|, |eab8|一无所有|eabb||eab1| |eab1||eabe|OLDHSK|eabf| |eab8|第(第一)|eabb|, |eab8|一|eabb|, |eab8|一般|eabb|, |eab8|一边|2026|一边|2026||eabb|, |eab8|一点儿|eabb|, |eab8|一定|eabb|, |eab8|一共|eabb|, |eab8|一会儿|eabb|, |eab8|一|2026|就|2026||eabb|, |eab8|一块儿|eabb|, |eab8|一起|eabb|, |eab8|一切|eabb|, |eab8|一下儿|eabb|, |eab8|一些|eabb|, |eab8|一样|eabb|, |eab8|一|2026|也|2026||eabb|, |eab8|一直|eabb|, |eab8|不一定|eabb|, |eab8|差一点儿|eabb|, |eab8|进一步|eabb|, |eab8|统一|eabb|, |eab8|一|eabb|, |eab8|一半|eabb|, |eab8|一边|eabb|, |eab8|一道|eabb|, |eab8|一方面|2026|一方面|2026||eabb|, |eab8|一齐|eabb|, |eab8|一生|eabb|, |eab8|一时|eabb|, |eab8|一同|eabb|, |eab8|一下子|eabb|, |eab8|一致|eabb|, |eab8|一|2026|也|eabb|, |eab8|有(一)点儿|eabb|, |eab8||2026|之一|eabb|, |eab8|万一|eabb|, |eab8|一一|eabb|, |eab8|一带|eabb|, |eab8|一路平安|eabb|, |eab8|一路顺风|eabb|, |eab8|一面|2026|一面|eabb|, |eab8|一系列|eabb|, |eab8|一下儿|eabb|, |eab8|一向|eabb|, |eab8|一再|eabb|, |eab8|一阵|eabb|, |eab8|一口气|eabb|, |eab8|一连|eabb|, |eab8|一旁|eabb|, |eab8|一心|eabb|, |eab8|一行|eabb|, |eab8|有(一)些|eabb|, |eab8|这样一来|eabb|, |eab8|老一辈|eabb|, |eab8|同一|eabb|, |eab8|唯一|eabb|, |eab8|一辈子|eabb|, |eab8|一旦|eabb|, |eab8|一度|eabb|, |eab8|一概|eabb|, |eab8|一概而论|eabb|, |eab8|一个劲儿|eabb|, |eab8|一贯|eabb|, |eab8|一哄而散|eabb|, |eab8|一会儿|2026|一会儿|eabb|, |eab8|一技之长|eabb|, |eab8|一律|eabb|, |eab8|一帆风顺|eabb|, |eab8|一干二净|eabb|, |eab8|一举|eabb|, |eab8|一毛不拔|eabb|, |eab8|一身|eabb|, |eab8|一手|eabb|, |eab8|一头|eabb||eab1| |eab1||eabe|HSK|eabf| |eab8|一|eabb|, |eab8|一点儿|eabb|, |eab8|第一|eabb|, |eab8|一起|eabb|, |eab8|一下|eabb|, |eab8|一般|eabb|, |eab8|一边|eabb|, |eab8|一定|eabb|, |eab8|一共|eabb|, |eab8|一会儿|eabb|, |eab8|一样|eabb|, |eab8|一直|eabb|, |eab8|一切|eabb|, |eab8|统一|eabb|, |eab8|万一|eabb|, |eab8|唯一|eabb|, |eab8|一辈子|eabb|, |eab8|一旦|eabb|, |eab8|一律|eabb|, |eab8|一再|eabb|, |eab8|一致|eabb|, |eab8|不屑一顾|eabb|, |eab8|一度|eabb|, |eab8|一帆风顺|eabb|, |eab8|一贯|eabb|, |eab8|一举两得|eabb|, |eab8|一流|eabb|, |eab8|一目了然|eabb|, |eab8|一如既往|eabb|, |eab8|一丝不苟|eabb|, |eab8|一向|eabb||eab1|\n",
    "\n",
    "\n",
    "'''\n",
    "def convert_to_num(match):\n",
    "    t = match.group(1)\n",
    "\n",
    "    if ord(t) < 256:\n",
    "        return t\n",
    "    else:\n",
    "        n = hex(ord(t)).replace('0x', '')\n",
    "        return f'|{n}|'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一\ty|12b|\t|eab2|HÁN VI|1ec6|T|eab3| |eab4|nh|1ea5|t|eab5||eab1||eab2|S|1ed0| T|1eea||eab3||eab1||eab2||2460||eab3| |eab2||eac1||ec00||ec00||ecbf||ecff|数目|ff0c|最小的正整数参看|3016|数字|3017||eac2||eab3| s|1ed1| m|1ed9|t; nh|1ea5|t; m|1ed9|t|eab1||eab1|\n"
     ]
    }
   ],
   "source": [
    "s='一\t\tone ❖ floor; ceiling PINYIN yī FRAME 1, LESSON 1, BOOK 1, PAGE  19 NAVIGATION ↑Lesson 1↑ (本书1第1课) »two» (二) SUBTLEX 一, 一个, 一起, 一样, 一下, 一直, 一切, 一点, 一定, 第一, 一些, 唯一, 一会儿, 一旦, 之一, 一半, 一边, 一般, 一生, 一刻, 一辈子, 一一, 一致, 一会, 一路, 万一, 一分, 一点儿, 一团糟, 一整天, 一面, 一百, 一无所知, 一两, 进一步, 一家, 一百万, 一时, 一千, 一模一样, 一阵子, 一向, 一共, 一阵, 同一个, 一万, 一番, 以防万一, 一下子, 星期一, 一无所有 OLDHSK 第(第一), 一, 一般, 一边…一边…, 一点儿, 一定, 一共, 一会儿, 一…就…, 一块儿, 一起, 一切, 一下儿, 一些, 一样, 一…也…, 一直, 不一定, 差一点儿, 进一步, 统一, 一, 一半, 一边, 一道, 一方面…一方面…, 一齐, 一生, 一时, 一同, 一下子, 一致, 一…也, 有(一)点儿, …之一, 万一, 一一, 一带, 一路平安, 一路顺风, 一面…一面, 一系列, 一下儿, 一向, 一再, 一阵, 一口气, 一连, 一旁, 一心, 一行, 有(一)些, 这样一来, 老一辈, 同一, 唯一, 一辈子, 一旦, 一度, 一概, 一概而论, 一个劲儿, 一贯, 一哄而散, 一会儿…一会儿, 一技之长, 一律, 一帆风顺, 一干二净, 一举, 一毛不拔, 一身, 一手, 一头 HSK 一, 一点儿, 第一, 一起, 一下, 一般, 一边, 一定, 一共, 一会儿, 一样, 一直, 一切, 统一, 万一, 唯一, 一辈子, 一旦, 一律, 一再, 一致, 不屑一顾, 一度, 一帆风顺, 一贯, 一举两得, 一流, 一目了然, 一如既往, 一丝不苟, 一向'\n",
    "s='一\tyī\tHÁN VIỆT nhấtSỐ TỪ① 数目，最小的正整数参看〖数字〗 số một; nhất; một'\n",
    "converted = re.sub(NORMAL, convert_to_num, s)\n",
    "print(converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "podcast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
